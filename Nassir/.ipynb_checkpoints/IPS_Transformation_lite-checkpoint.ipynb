{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "import numpy as np\n",
    "from sas7bdat import SAS7BDAT\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "# modify or remove these as appropriate\n",
    "path_to_test_file = r\"\\\\nsdata3\\Social_Surveys_team\\CASPA\\IPS\\Testing\\crossingfactor\\test.txt\"\n",
    "path_to_survey_data = r\"\\\\nsdata3\\Social_Surveys_team\\CASPA\\IPS\\Testing\\crossingfactor\\surveydata.sas7bdat\"\n",
    "path_to_shifts_data = r\"\\\\nsdata3\\Social_Surveys_team\\CASPA\\IPS\\Testing\\crossingfactor\\shiftsdata.sas7bdat\"\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# function definitions\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# load sas file and convert to a pandas dataframe\n",
    "def load_sas(sasfile, encoding=\"utf8\", encoding_errors=\"replace\"):\n",
    "\n",
    "    with SAS7BDAT(sasfile, encoding=encoding,encoding_errors=encoding_errors) as sas:\n",
    "        sas = iter(sas)\n",
    "        columns = [c for c in next(sas)]\n",
    "        df = pd.DataFrame(sas, columns=columns)\n",
    "        return df\n",
    "    \n",
    "# -----------------------------------------------------\n",
    "#load sas files into dataframes\n",
    "# -----------------------------------------------------\n",
    "\n",
    "df_survey_data = load_sas(path_to_survey_data)\n",
    "df_shifts_data = load_sas(path_to_shifts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# assign all the variable values and make upper case\n",
    "# as all table column names are upper case\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# ShiftsStratumDef = Variable holding the shift weight stratum definition\n",
    "StratumDef_temp = [\"shift_port_grp_pv\", \"arrivedepart\", \"weekday_end_pv\", \"am_pm_night_pv\"] #ShiftsStratumDef\n",
    "\n",
    "# table fields are upper case, so require conversion to upper case\n",
    "StratumDef = list(map(lambda x: x.upper(), StratumDef_temp))\n",
    "\n",
    "# crossingFlag = variable that indicates that this record is crossing \n",
    "crossingFlag = \"crossings_flag_pv\".upper() #var_crossingFlag \n",
    "\n",
    "# var_shiftNumber = Variable holding the shift number\n",
    "shiftNumber = \"shiftno\".upper() #var_shiftNumber\n",
    "\n",
    "# var_crossingNumber = Variable holding the crossing number\n",
    "crossingNumber = \"shuttle\".upper() #var_crossingNumber\n",
    "\n",
    "# var_crossingsFactor = Variable holding the name of the crossings factor\n",
    "crossingsFactor = \"crossings_factor\" # it is lower case.upper() #var_crossingsFactor\n",
    "\n",
    "# var_totals = Variable holding the number of possible shifts / total\n",
    "totals = \"total\".upper() #var_totals\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# set the new dataframes from SAS datasets\n",
    "# -----------------------------------------------------\n",
    "df_crossingsData = df_shifts_data # (334, 9)\n",
    "df_outputData = df_survey_data # shape=(26347, 212)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Get survey records that are crossing based\n",
    "# -----------------------------------------------------\n",
    "df_sampled_crossings = df_survey_data.loc[df_survey_data[crossingFlag] == 1] # shape=(3084, 212)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# calculate the number of sampled crossings by strata \n",
    "# -----------------------------------------------------\n",
    "\n",
    "# keep, sort and drop duplicates\n",
    "selected_columns = StratumDef + [shiftNumber, crossingNumber]\n",
    "\n",
    "temp_d1 = df_sampled_crossings[selected_columns]\n",
    "df_sorted_sampled_crossings = temp_d1.sort_values(selected_columns).drop_duplicates()# shape= (180,6)\n",
    "\n",
    "# reindex the dataframe\n",
    "df_sorted_sampled_crossings.index = range(df_sorted_sampled_crossings.shape[0])\n",
    "\n",
    "# note - we require reset_index() here to compose the correctly laid out dataframe\n",
    "df_totalSampledCrossings = df_sorted_sampled_crossings.groupby(StratumDef)[crossingNumber]\\\n",
    "                                                 .agg(OrderedDict([('_FREQ_', 'count'),('denominator', 'count')]))\\\n",
    "                                                 .reset_index() # shape = (36, 6)\n",
    "\n",
    "# note - not required but put incase required in future for similar\n",
    "df_totalSampledCrossings.index = range(df_totalSampledCrossings.shape[0])\n",
    "\n",
    "# insert the constant class type in this case as no class specified in SAS proc\n",
    "df_totalSampledCrossings.insert(4, \"_TYPE_\", 0)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# calculate the total number of crossings by strata\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# sort the data (if required)\n",
    "df_sorted_crossingsData = df_crossingsData.sort_values(StratumDef)\n",
    "\n",
    "# note - we require reset_index() here to compose the correctly laid out dataframe\n",
    "df_totalCrossings = df_sorted_crossingsData.groupby(StratumDef)[totals]\\\n",
    "                                                 .agg(OrderedDict([('_FREQ_', 'count'),('numerator', 'sum')]))\\\n",
    "                                                 .reset_index() # shape = (36, 6)        \n",
    "\n",
    "df_totalCrossings.index = range(df_totalCrossings.shape[0])\n",
    "\n",
    "# insert the constant class type in this case as no class specified in SAS proc\n",
    "df_totalCrossings.insert(4, \"_TYPE_\", 0)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# now compute the crossings factor \n",
    "# -----------------------------------------------------\n",
    "\n",
    "df_sorted_outputData = df_outputData.sort_values(StratumDef)\n",
    "\n",
    "df_sorted_outputData #keep all\n",
    "df_totalCrossings  = df_totalCrossings[StratumDef + ['numerator']] # keep &StratumDef numerator\n",
    "df_totalSampledCrossings = df_totalSampledCrossings[StratumDef + ['denominator']] # (keep = &StratumDef denominator);\n",
    "\n",
    "left_join_1 = df_sorted_outputData.merge(df_totalCrossings, on=StratumDef, how='left')\\\n",
    "                                  .merge(df_totalSampledCrossings, on=StratumDef, how='left')\n",
    "\n",
    "# if crossingFlag column not equal 1:\n",
    "#    if denominator not equal 0:\n",
    "#        crossing_factor_column = numerator/denominator\n",
    "#function for calculating the crossings factor through mapping columns\n",
    "def g(row):\n",
    "    if(row[crossingFlag] != 0 and row['denominator'] != 0):        \n",
    "        return row['numerator']/row['denominator']       \n",
    "    else:       \n",
    "        return None\n",
    "\n",
    "# calculate crossings factor    \n",
    "left_join_1[crossingsFactor] = left_join_1.apply(g, axis=1)\n",
    "\n",
    "# drop numerator and denominator columns\n",
    "df_final = left_join_1.drop(['numerator', 'denominator'], 1)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
